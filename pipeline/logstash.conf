input {
  elasticsearch {
    id => hourly_cron_job
    hosts => [ 'http://elasticsearch:9200/']
    query_type => 'esql'
    query => 'FROM .ds-kibana_sample_data_logs-* | WHERE @timestamp >= "2025-10-01T00:00:00.000Z" AND @timestamp < "2025-11-01T00:00:00.000Z" | EVAL es_timestamp = DATE_TRUNC(1 hour, @timestamp) | STATS status_code_200_counter = COUNT(*) WHERE response == "200", status_code_5xx_counter = COUNT(*) WHERE response >= "500" AND response < "600" BY es_timestamp | SORT es_timestamp'
    schedule => '* * * * *'
  }
}

# filter {
#   # Genera un evento por fila del array "values"
#   split { field => "[values]" }

#   # Mapear dinámicamente nombre de columnas -> valores
#   ruby {
#     code => '
#       cols = event.get("columns")
#       row  = event.get("values")
#       if cols && row
#         cols.each_with_index do |c,i|
#           event.set(c["name"], row[i])
#         end
#       end
#     '
#   }

#   # Convertir tipos
#   mutate {
#     convert => {
#       "status_code_200_counter" => "integer"
#       "status_code_500_counter" => "integer"
#     }
#   }

#   # (Opcional) parsear timestamps a tipo date (crea @timestamp según last_occurrence)
#   # date {
#   #   match => ["last_occurrence", "ISO8601"]
#   #   target => "@timestamp"
#   #   remove_field => []
#   # }

#   # Eliminar todo lo que no sea los campos finales deseados
#   mutate {
#     remove_field => [
#       "values",
#       "columns",
#       "http_poller_metadata",
#       "host",
#       "@version",
#       "event",
#       "agent"
#     ]
#   }
# }

output {

  mongodb {
    uri => "mongodb://admin:1q2w3E*@mongodb:27017/?authSource=admin"
    database => "logsdb"
    collection => "grouped_response_code"
    isodate => true
  }

  stdout { codec => rubydebug }
}